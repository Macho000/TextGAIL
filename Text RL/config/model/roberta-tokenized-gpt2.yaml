model:
    initializer_range: 0.02
    layer_norm_epsilon: 1e-05
    n_ctx: 1024
    n_embd: 768
    n_head: 12
    n_layer: 12
    n_positions: 1024
    vocab_size: 50265
    embd_pdrop: 0.0
    resid_pdrop: 0.0
    attn_pdrop: 0.0
    output_attentions: false
    output_hidden_states: false
    output_past: true
    pad_token_id: 1
    name: roberta-tokenized-gpt2