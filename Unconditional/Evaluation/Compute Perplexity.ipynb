{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import hydra.experimental\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import RobertaTokenizer\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from torchfly.text.decode import TransformerDecoder\n",
    "from torchfly.common import set_random_seed, move_to_device\n",
    "\n",
    "from configure_dataloader import DataLoaderHandler\n",
    "from model import Generator, TextGAILModel\n",
    "\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify the weight path for evaluation\n",
    "textgail_weights_path = \"\"\n",
    "mle_weights_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_handler = DataLoaderHandler(config)\n",
    "test_dataloader = dataloader_handler.test_dataloader(config)\n",
    "# collate_fn = dataloader_handler.collator.sample_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGAILModel(config)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mle_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = (np.arange(3, 10, 1) + 1) / 10.0\n",
    "print(temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_weights = torch.load(mle_weights_path)\n",
    "model.generator.load_state_dict(mle_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle = []\n",
    "for temperature in temperatures:\n",
    "    for batch in tqdm.tqdm(test_dataloader):\n",
    "        batch = move_to_device(batch, device)\n",
    "        batch[\"temperature\"] = temperature\n",
    "\n",
    "        model.predict(batch)\n",
    "    metrics = model.get_metrics(reset=True)\n",
    "    mle.append(metrics['perplexity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextGAIL Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textgail_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgail_weights = torch.load(textgail_weights_path)\n",
    "model.load_state_dict(textgail_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgail = []\n",
    "for temperature in temperatures:\n",
    "    for batch in tqdm.tqdm(test_dataloader):\n",
    "        batch = move_to_device(batch, device)\n",
    "        batch[\"temperature\"] = temperature\n",
    "\n",
    "        model.predict(batch)\n",
    "    metrics = model.get_metrics(reset=True)\n",
    "    textgail.append(metrics['perplexity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textgail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store the intermediate results\n",
    "# with open(f\"{config.task.name}_perplexity.txt\", \"w\") as f:\n",
    "#     line = json.dumps({\"mle\": mle, \"textgail\": textgail})\n",
    "#     f.write(line)\n",
    "#     f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.task.name = \"EMNLP_NEWS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{config.task.name}_perplexity.txt\") as f:\n",
    "    data = json.loads(f.read())\n",
    "mle = data[\"mle\"]\n",
    "textgail = data[\"textgail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax.plot(temperatures, mle, marker=\"o\", color=\"r\", ls=\"--\")\n",
    "ax.plot(temperatures, textgail, marker=\"*\", color=\"b\")\n",
    "ax.legend([\"GPT-2+MLE\", \"TextGAIL\"])\n",
    "ax.set_xlabel(\"Temperature\", fontsize=18)\n",
    "ax.set_ylabel(\"Perplexity\", fontsize=18)\n",
    "ax.set_title(f\"Perplexity vs. Temperature\")\n",
    "\n",
    "# major_ticks = np.arange(10, 40, 5)\n",
    "# ax.set_yticks(major_ticks)\n",
    "ax.set_xticks(temperatures)\n",
    "\n",
    "ax.grid(\"on\")\n",
    "\n",
    "plt.savefig(f\"{config.task.name} perplexity.png\", dpi=300, pad_inches=0.1, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}