{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import hydra.experimental\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import RobertaTokenizer\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from torchfly.text.decode import TransformerDecoder\n",
    "from torchfly.common import set_random_seed, move_to_device\n",
    "\n",
    "from configure_dataloader import DataLoaderHandler\n",
    "from model import Generator, TextGAILModel\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "set_random_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.experimental.initialize(\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = hydra.experimental.compose(\"config.yaml\")\n",
    "print(config.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_handler = DataLoaderHandler(config)\n",
    "test_dataloader = dataloader_handler.test_dataloader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGAILModel(config)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = TransformerDecoder(config.decode)\n",
    "decoder.register_generator(model.generator.decoder)\n",
    "decoder.register_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location where the generations will be stored\n",
    "os.makedirs(config.task.name,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please make sure you have specified the corresponding MLE weight path and TextGAIL weights path\n",
    "print(config.task.mle_weights_path)\n",
    "print(config.task.textgail_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = (np.arange(5) + 1) / 5.0\n",
    "print(temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_weights = torch.load(config.task.mle_weights_path)\n",
    "model.generator.load_state_dict(mle_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temperature in temperatures:\n",
    "    f_write = open(f\"{config.task.name}/mle_{temperature}_{random_seed}.txt\", \"w\")\n",
    "\n",
    "    for i in tqdm.trange(100):\n",
    "\n",
    "        results = decoder.generate(input_ids, temperature=temperature)\n",
    "        generated = []\n",
    "\n",
    "        for i in range(len(results[\"tokens\"])):\n",
    "            res = tokenizer.decode(results[\"tokens\"][i][0][1:-1].tolist())\n",
    "            generated.append(res)\n",
    "\n",
    "        for gen in generated:\n",
    "            f_write.write(json.dumps(gen))\n",
    "            f_write.write(\"\\n\")\n",
    "        \n",
    "    f_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextGAIL Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgail_weights = torch.load(config.task.textgail_weights_path)\n",
    "model.load_state_dict(textgail_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temperature in temperatures:\n",
    "    f_write = open(f\"{config.task.name}/textgail_{temperature}_{random_seed}.txt\", \"w\")\n",
    "\n",
    "    for i in tqdm.trange(100):\n",
    "        results = decoder.generate(input_ids, temperature=temperature)\n",
    "        generated = []\n",
    "\n",
    "        for i in range(len(results[\"tokens\"])):\n",
    "            res = tokenizer.decode(results[\"tokens\"][i][0][1:-1].tolist())\n",
    "            generated.append(res)\n",
    "\n",
    "        for gen in generated:\n",
    "            f_write.write(json.dumps(gen))\n",
    "            f_write.write(\"\\n\")\n",
    "        \n",
    "    f_write.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda2c389d1998144387b42705ad1fa3874e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}